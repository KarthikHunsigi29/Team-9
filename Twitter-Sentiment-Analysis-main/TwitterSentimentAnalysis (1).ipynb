{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0e148f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import unicodedata\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e71be5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('TwitterHate.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b019f803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b851b260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31962 entries, 0 to 31961\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      31962 non-null  int64 \n",
      " 1   label   31962 non-null  int64 \n",
      " 2   tweet   31962 non-null  object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 749.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8ded0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52d579cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              tweet\n",
       "0      0   @user when a father is dysfunctional and is s...\n",
       "1      0  @user @user thanks for #lyft credit i can't us...\n",
       "2      0                                bihday your majesty\n",
       "3      0  #model   i love u take with u all the time in ...\n",
       "4      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eefcee98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label    0\n",
       "tweet    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2fb4aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7350811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8170f98a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     @user when a father is dysfunctional and is s...\n",
       "1    @user @user thanks for #lyft credit i can't us...\n",
       "2                                  bihday your majesty\n",
       "3    #model   i love u take with u all the time in ...\n",
       "4               factsguide: society now    #motivation\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet']=df['tweet'].str.lower()\n",
    "df['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afc97ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28f46656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STOPWORDS = set(stopwords.words('english'))\n",
    "# def cleaningStopwords(text):\n",
    "#     return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "# df['tweet'] = df['tweet'].apply(lambda text: cleaningStopwords(text))\n",
    "# df['tweet'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca75233b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2738     today beautiful day . time 2 remember beautifu...\n",
       "29476    @ user good morning rj ji # jiyodilse # salaam...\n",
       "31467                hi ! # paytoday snapchat : sandy-9791\n",
       "9261     going miss cheeky birdie next 12 days ! ! ! # ...\n",
       "3413     beautiful bobo ! love ! # friends # dinner # p...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "def cleaningStopwords(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    filtered_tokens = [token for token in tokens if token.lower() not in STOPWORDS]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "df['tweet'] = df['tweet'].apply(lambda text: cleaningStopwords(text))\n",
    "df['tweet'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d2ce544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9218     happy weddingâ¤ï¸  çµå©å¼ wedding  ãå¹¸...\n",
       "21341    hea  user  porsche  photo  photography  fun  l...\n",
       "10017    really  dancing street  streetdance  tinydance...\n",
       "10246                 thankful health   thankful  positive\n",
       "19563    today notice sounds  health  user  user  user ...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "english_punctuations = string.punctuation\n",
    "punctuations_list = english_punctuations\n",
    "def cleaningPunctuations(text):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(translator)\n",
    "df['tweet'] = df['tweet'].apply(lambda x: cleaningPunctuations(x))\n",
    "df['tweet'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4357e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5727      user today going good day ððð¡ð¤ð...\n",
       "8758      user preparations underway   user  user  user...\n",
       "26793     user  fridayfeeling tweeters  user  user  che...\n",
       "18602    ve never seen bigger  happier  smile   bighapp...\n",
       "25686     user let s vote  ë¹ ì¤  ëì¼  user  060521...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleaningRepeatingChar(text):\n",
    "    return re.sub(r'(.)1+', r'1', text)\n",
    "df['tweet'] = df['tweet'].apply(lambda x: cleaningRepeatingChar(x))\n",
    "df['tweet'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5749bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24544        user thankful new places   thankful  positive\n",
       "19001    playing  abandoned toys   spiraling sun  music...\n",
       "19346    chill  ðð » ðð¹  thankful  blessed  ...\n",
       "24351     marathon bull  dominate bull direct whatever ...\n",
       "16565     guy ask change  gave pocket lit cigarette wal...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleaningURLs(data):\n",
    "    return re.sub('((www.[^s]+)|(https?://[^s]+))',' ',data)\n",
    "df['tweet'] = df['tweet'].apply(lambda x: cleaningURLs(x))\n",
    "df['tweet'].sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f14da0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14670       thankful family vacations   thankful  positive\n",
       "4059     jessica dona asian beauty gives happy ending m...\n",
       "9293     ca nt secular education haredi life  existed b...\n",
       "30153     user make  quitting  cigarettes  gift loved o...\n",
       "19237    little things make fianally got order  india  ...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleaningNumbers(data):\n",
    "    return re.sub('[0-9]+', '', data)\n",
    "df['tweet'] = df['tweet'].apply(lambda x: cleaningNumbers(x))\n",
    "df['tweet'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4a402e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0c31612",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet'] = df['tweet'].apply(lambda x: remove_accented_chars(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e57f90d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12363    bahoom   funny  humor  jokes  joke  wordplay  ...\n",
       "10958     user s s happening twitter  m engaged amazing...\n",
       "14355    handsome guy join anchor desk tonight   amp   ...\n",
       "26394     user  user exactly  feel m butt end giant com...\n",
       "11927     germanyhetalia bull  dominate bull direct wha...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c26eab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load('en_core_web_sm')\n",
    "def lemmatize_text(text):\n",
    "    text = nlp(text)\n",
    "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e453399d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet'] = df['tweet'].apply(lambda x: lemmatize_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7b61918",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['tweet']\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, stratify=y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b60bea78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25569,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb0cf30b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25569,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de810779",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1f972c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize text reviews to numbers\n",
    "X_train_vec = vec.fit_transform(X_train).toarray()\n",
    "X_test_vec = vec.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66162fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=10)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators = 10)\n",
    "classifier.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01bb76fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "acbfe28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[5925   20]\n",
      " [ 244  204]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      5945\n",
      "           1       0.91      0.46      0.61       448\n",
      "\n",
      "    accuracy                           0.96      6393\n",
      "   macro avg       0.94      0.73      0.79      6393\n",
      "weighted avg       0.96      0.96      0.95      6393\n",
      "\n",
      "Accuracy: 0.9587048334115439\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "result = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(result)\n",
    "result1 = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\",)\n",
    "print (result1)\n",
    "result2 = accuracy_score(y_test,y_pred)\n",
    "print(\"Accuracy:\",result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47b3e505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[5889   56]\n",
      " [ 302  146]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      5945\n",
      "           1       0.72      0.33      0.45       448\n",
      "\n",
      "    accuracy                           0.94      6393\n",
      "   macro avg       0.84      0.66      0.71      6393\n",
      "weighted avg       0.94      0.94      0.93      6393\n",
      "\n",
      "Accuracy: 0.9440012513686845\n"
     ]
    }
   ],
   "source": [
    "adaclassifier = AdaBoostClassifier(n_estimators = 50)\n",
    "adaclassifier.fit(X_train_vec, y_train)\n",
    "y_pred = adaclassifier.predict(X_test_vec)\n",
    "result = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(result)\n",
    "result1 = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\",)\n",
    "print (result1)\n",
    "result2 = accuracy_score(y_test,y_pred)\n",
    "print(\"Accuracy:\",result2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
